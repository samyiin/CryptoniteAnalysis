{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"97e85fae8bdb402db3a989687d3d6dbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1ed1cb713094aae8a95db63c9b2881c","IPY_MODEL_83fde72fbdfa485fa45727279fb67349","IPY_MODEL_a5edd04125f440fc93af024d440c249e"],"layout":"IPY_MODEL_0a215093358a4b57979e4f7171e80a98"}},"d1ed1cb713094aae8a95db63c9b2881c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2186989c64904cb3bdf8840847025c1d","placeholder":"​","style":"IPY_MODEL_8a1377c5c3044bfd805c70c28170c0f7","value":"Filter: 100%"}},"83fde72fbdfa485fa45727279fb67349":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02310bdea4554815b9c338eb4796d5d4","max":470852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c59788995324382a494493bcf8f0d54","value":470852}},"a5edd04125f440fc93af024d440c249e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff5a9d33a2bb43aa9de7d5ecb1c7ef10","placeholder":"​","style":"IPY_MODEL_124ea7eaa5274aecb8acb59c19f4b623","value":" 470852/470852 [00:17&lt;00:00, 38636.12 examples/s]"}},"0a215093358a4b57979e4f7171e80a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2186989c64904cb3bdf8840847025c1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a1377c5c3044bfd805c70c28170c0f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02310bdea4554815b9c338eb4796d5d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c59788995324382a494493bcf8f0d54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff5a9d33a2bb43aa9de7d5ecb1c7ef10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"124ea7eaa5274aecb8acb59c19f4b623":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"804b04349c0d4fbe9c8fc70a07e5c67c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b630157fb31d4f97b3da504c4d7c7835","IPY_MODEL_f86fa666217a4786a95bfd98386bae46","IPY_MODEL_a2452758778b42569d1f3341a7a6e36e"],"layout":"IPY_MODEL_381eea6101574ef59b00b7f75bca64d9"}},"b630157fb31d4f97b3da504c4d7c7835":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6deb57256b764788a326b4c1750508c7","placeholder":"​","style":"IPY_MODEL_3e71365f85d340d1921640d64285d308","value":"Filter: 100%"}},"f86fa666217a4786a95bfd98386bae46":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d074686ec7942f38f317834aa0992dd","max":26204,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0648ca75ff6495daa9bcaa3d8a728fc","value":26204}},"a2452758778b42569d1f3341a7a6e36e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fd607beac3245eeaa27947d1aad472b","placeholder":"​","style":"IPY_MODEL_baa6f4b5f58043d18ea34ddea479a35d","value":" 26204/26204 [00:00&lt;00:00, 36178.99 examples/s]"}},"381eea6101574ef59b00b7f75bca64d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6deb57256b764788a326b4c1750508c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e71365f85d340d1921640d64285d308":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d074686ec7942f38f317834aa0992dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0648ca75ff6495daa9bcaa3d8a728fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fd607beac3245eeaa27947d1aad472b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baa6f4b5f58043d18ea34ddea479a35d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"935c542cc5e0467e8e73d46326fdecfb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95254117931141909381645494be5a2c","IPY_MODEL_769f71ff3c5045c4a2b2de0e09aec3b4","IPY_MODEL_a05a71131b15496aa6015cb1de58003d"],"layout":"IPY_MODEL_50e3fd6ca1d3482cb7ef8825a929e70f"}},"95254117931141909381645494be5a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abcba5d04ec54689aad9b86959288e99","placeholder":"​","style":"IPY_MODEL_c36038de8d8b47cc9521b8031601faee","value":"Filter: 100%"}},"769f71ff3c5045c4a2b2de0e09aec3b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aef690deb0642e1bce60501f4d4a67d","max":26205,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c597f6537e66456c84a42804c7abe23e","value":26205}},"a05a71131b15496aa6015cb1de58003d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fcaecb891c04bc4ad1c92d9f5e22837","placeholder":"​","style":"IPY_MODEL_4ffc7f13a0b941caa84196860bf3ac77","value":" 26205/26205 [00:00&lt;00:00, 38174.74 examples/s]"}},"50e3fd6ca1d3482cb7ef8825a929e70f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abcba5d04ec54689aad9b86959288e99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c36038de8d8b47cc9521b8031601faee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6aef690deb0642e1bce60501f4d4a67d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c597f6537e66456c84a42804c7abe23e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5fcaecb891c04bc4ad1c92d9f5e22837":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ffc7f13a0b941caa84196860bf3ac77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f7ae90b3f0e40228388eb8f2be14c64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd7d56a38c604dbbacbb1e7af7d200cb","IPY_MODEL_e03f90459be8449aa36de54f4cf9a0c5","IPY_MODEL_68f99457a7934e3dbd63055b1e9f8b58"],"layout":"IPY_MODEL_137027f960c64dbea8447353bb53daa4"}},"fd7d56a38c604dbbacbb1e7af7d200cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0abb9dba99d1461399814adbf9552309","placeholder":"​","style":"IPY_MODEL_5f21d8f9cd584cadb74ba83cac2f1004","value":"Filter: 100%"}},"e03f90459be8449aa36de54f4cf9a0c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e6cea4b250640b7bc64c45ce6f7b4c3","max":470852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7362a2cd22504914bb67fa3fdbb22572","value":470852}},"68f99457a7934e3dbd63055b1e9f8b58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29115e63703345b2b94d068431083b7e","placeholder":"​","style":"IPY_MODEL_90bf9eb5e04d40429f3d21f28564679f","value":" 470852/470852 [00:15&lt;00:00, 36195.10 examples/s]"}},"137027f960c64dbea8447353bb53daa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0abb9dba99d1461399814adbf9552309":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f21d8f9cd584cadb74ba83cac2f1004":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e6cea4b250640b7bc64c45ce6f7b4c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7362a2cd22504914bb67fa3fdbb22572":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29115e63703345b2b94d068431083b7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90bf9eb5e04d40429f3d21f28564679f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbaf7d6f23504741839ccff7e3d63a0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_136c0414109547918aab42f45fbed20d","IPY_MODEL_6a1064ed48e34e1092d3bf86bc40a555","IPY_MODEL_7f7599481f3e4890a8014a0879525627"],"layout":"IPY_MODEL_9e2800cb67604a18abe8e77589144601"}},"136c0414109547918aab42f45fbed20d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5503edea32f49e19f2d977a5ceee449","placeholder":"​","style":"IPY_MODEL_313f9bd777a346a18f326ab8c7904967","value":"Filter: 100%"}},"6a1064ed48e34e1092d3bf86bc40a555":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ccc546d2ce45418d1f532768ef2727","max":26204,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9358584b9d654a909c569bb6656eb06a","value":26204}},"7f7599481f3e4890a8014a0879525627":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c59fbcbc68240a0896a1f153c9498ab","placeholder":"​","style":"IPY_MODEL_7aa78b46b7c5431ebfc8e40b4688eec4","value":" 26204/26204 [00:00&lt;00:00, 34677.94 examples/s]"}},"9e2800cb67604a18abe8e77589144601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5503edea32f49e19f2d977a5ceee449":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"313f9bd777a346a18f326ab8c7904967":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03ccc546d2ce45418d1f532768ef2727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9358584b9d654a909c569bb6656eb06a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c59fbcbc68240a0896a1f153c9498ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aa78b46b7c5431ebfc8e40b4688eec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ce0725a975b4afa8176e8cdf0e6ed7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56e27008c83c4a819aa29b9998d07cdf","IPY_MODEL_b56dfd9dabb84fd8a6ee20df725623a7","IPY_MODEL_667964eed9d24ab396197e153e972219"],"layout":"IPY_MODEL_133948056adf4610a5321e677642ab89"}},"56e27008c83c4a819aa29b9998d07cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd185af71dda44e69d35305fae71509e","placeholder":"​","style":"IPY_MODEL_4a47b368924d45c0bde64493e36fff25","value":"Filter: 100%"}},"b56dfd9dabb84fd8a6ee20df725623a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4a0b36a475d49679505dcae47f948c3","max":26205,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94e70a78f793480ab5e8bb5fa3b57559","value":26205}},"667964eed9d24ab396197e153e972219":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44249b81909f43aea31d91315ad1cead","placeholder":"​","style":"IPY_MODEL_0b87a93848f44bfba1dd85d20ca19dbc","value":" 26205/26205 [00:00&lt;00:00, 33869.78 examples/s]"}},"133948056adf4610a5321e677642ab89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd185af71dda44e69d35305fae71509e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a47b368924d45c0bde64493e36fff25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4a0b36a475d49679505dcae47f948c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94e70a78f793480ab5e8bb5fa3b57559":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44249b81909f43aea31d91315ad1cead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b87a93848f44bfba1dd85d20ca19dbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc3d415427e84a3f84cae38f7e507e2a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c85f4ecfd88a46e4ab54b43f37309de8","IPY_MODEL_03ef5564247d49c6ad8ebb4363a6bc52","IPY_MODEL_103541d5fa024060ae70800e38179973"],"layout":"IPY_MODEL_b1b46c63023a4dee87581eae2ffc487f"}},"c85f4ecfd88a46e4ab54b43f37309de8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f9a49fc00b546e299310c0842e81fff","placeholder":"​","style":"IPY_MODEL_7187bae751514e3f94501a49e541177e","value":"Filter: 100%"}},"03ef5564247d49c6ad8ebb4363a6bc52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2ed5d70b3f34beda475747a528b8410","max":470852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da89f5bca2e54337b95434fb61002ab3","value":470852}},"103541d5fa024060ae70800e38179973":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4d4dada93184e9c89720be3e32d49d0","placeholder":"​","style":"IPY_MODEL_69cec636f2eb4d37bd50ecc555da2cb4","value":" 470852/470852 [00:14&lt;00:00, 36345.94 examples/s]"}},"b1b46c63023a4dee87581eae2ffc487f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f9a49fc00b546e299310c0842e81fff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7187bae751514e3f94501a49e541177e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2ed5d70b3f34beda475747a528b8410":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da89f5bca2e54337b95434fb61002ab3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4d4dada93184e9c89720be3e32d49d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69cec636f2eb4d37bd50ecc555da2cb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d42c48d1a4d403c9ffee2d61ace185a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de77ca8dec9b44bc929aa5988955200c","IPY_MODEL_d1726d1807d84c6cbf601d81b46c454e","IPY_MODEL_b386a7f20ebc41aeb1a1fdf97522e7c4"],"layout":"IPY_MODEL_c1665367e283484898ec119b18ffdd56"}},"de77ca8dec9b44bc929aa5988955200c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9c4aa4aaee04d3ca49551b13de2111b","placeholder":"​","style":"IPY_MODEL_8056d88516dd44d1a9b550f509643caf","value":"Filter: 100%"}},"d1726d1807d84c6cbf601d81b46c454e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b4da3b5d2b4eb2a0ad85b63dc7f0ff","max":26204,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6cdaac3c4d544cd7ae07cb91354fb7c7","value":26204}},"b386a7f20ebc41aeb1a1fdf97522e7c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4cdba5307df4dfb8796b1f4877fcb61","placeholder":"​","style":"IPY_MODEL_1f0da75170f54ee59457f51da5339f7d","value":" 26204/26204 [00:00&lt;00:00, 35239.27 examples/s]"}},"c1665367e283484898ec119b18ffdd56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9c4aa4aaee04d3ca49551b13de2111b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8056d88516dd44d1a9b550f509643caf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6b4da3b5d2b4eb2a0ad85b63dc7f0ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cdaac3c4d544cd7ae07cb91354fb7c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4cdba5307df4dfb8796b1f4877fcb61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f0da75170f54ee59457f51da5339f7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec9fdad12bb9488cab78219abbc2e80d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_261442dc144f4987b7bd5eee197fd900","IPY_MODEL_b8b8f8aaa88346668f6481792571dd69","IPY_MODEL_b2916674b17c4679bbd623acd18c7e77"],"layout":"IPY_MODEL_7574f1334a2b402c9ed0a4978c615ce7"}},"261442dc144f4987b7bd5eee197fd900":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f2d1f7947394cea83ba24c41ab7a224","placeholder":"​","style":"IPY_MODEL_64436853845f4db1963cdff42c41a613","value":"Filter: 100%"}},"b8b8f8aaa88346668f6481792571dd69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5d3b558cbbd4453b8cad7022a7af121","max":26205,"min":0,"orientation":"horizontal","style":"IPY_MODEL_307f9f71bd4e4bd887e1bd5272a5ddbb","value":26205}},"b2916674b17c4679bbd623acd18c7e77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b14f2b4a833a4a3f878a376c7ed9dff4","placeholder":"​","style":"IPY_MODEL_754006ba552d45748d07d7da690c9f53","value":" 26205/26205 [00:01&lt;00:00, 21118.34 examples/s]"}},"7574f1334a2b402c9ed0a4978c615ce7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f2d1f7947394cea83ba24c41ab7a224":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64436853845f4db1963cdff42c41a613":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5d3b558cbbd4453b8cad7022a7af121":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"307f9f71bd4e4bd887e1bd5272a5ddbb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b14f2b4a833a4a3f878a376c7ed9dff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"754006ba552d45748d07d7da690c9f53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Load Chatbot\n"],"metadata":{"id":"P01u8aerZXeo"}},{"cell_type":"code","source":["!pip install openai\n","!pip install datasets\n","from datasets import load_dataset, load_from_disk\n","import openai\n","import google.generativeai as genai\n","\n","import os\n","import copy\n","import ast\n","from collections import Counter\n","import re\n","!pip install datasets\n","!pip install -q -U google-generativeai\n","\n","\n","# Mount to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change it to your google drive path where this notebook located.\n","drive_path = '/content/drive/MyDrive/Projects/CryptoniteAnalysis/'\n","os.chdir(drive_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWPHXI734rzS","executionInfo":{"status":"ok","timestamp":1726320999427,"user_tz":-180,"elapsed":77882,"user":{"displayName":"Sam Yiin","userId":"15309663941607315772"}},"outputId":"263e31cd-13f5-4122-91fe-88f7b93c8af1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting jiter<1,>=0.4.0 (from openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n","Downloading openai-1.45.0-py3-none-any.whl (374 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.45.0\n","Collecting datasets\n","  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.4/725.4 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hMounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kevp5MfKYDfT"},"outputs":[],"source":["# @title GPT Chatbot\n","API_KEY=\"YOUR OPENAI API KEY\"\n","\n","# define the openai interface\n","def try_query_GPT(**request_body):\n","    client = openai.OpenAI(api_key=API_KEY)\n","    response = client.chat.completions.create(**request_body)\n","    return response\n","\n","def accept_gpt_response(response):\n","    res_stop = True\n","    # first check if the response is complete\n","    if not response.choices[0].finish_reason == \"stop\":\n","        res_stop = False\n","\n","    # Other checks in the future\n","    return res_stop\n","\n","def query_GPT(**request_body):\n","    response = try_query_GPT(**request_body)\n","    # if response failed\n","    timeout = 0\n","    while not accept_gpt_response(response):\n","        response = try_query_GPT(**request_body)\n","        timeout += 1\n","        if timeout > 10:\n","            raise Exception(\"Query failed\")\n","    return response.choices[0].message.content\n","\n","default_request_body = {\n","    \"model\": \"gpt-4o-mini\",\n","    \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}],\n","    \"temperature\": 0.7,\n","}\n","\n","\n","class GPTChatBot:\n","    def __init__(self, initial_request_body=default_request_body):\n","        if \"messages\" not in initial_request_body:\n","            raise ValueError(\"messages not in request_body\")\n","        if \"model\" not in initial_request_body:\n","            raise ValueError(\"model not in request_body\")\n","        self.initial_request_body = copy.deepcopy(initial_request_body)\n","\n","        self.chat_history = self.initial_request_body[\"messages\"]\n","\n","    def chat(self, prompt):\n","        # query ChatGPT, but do not add the conversation to history\n","        temp_request_body = copy.deepcopy(self.initial_request_body)\n","        temp_request_body[\"messages\"].append({\"role\": \"user\", \"content\": prompt})\n","        response = query_GPT(**temp_request_body)\n","        return response\n","\n","    def set_chat_history(self, chat_history):\n","        self.chat_history = chat_history\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"til404ksb7qX"},"outputs":[],"source":["# @title Gemini Chatbot\n","GEMINI_KEY=\"YOUR GEMINI API KEY\"\n","\n","# define the openai interface\n","def try_query_Gemini(**request_body):\n","    model = request_body[\"model\"]\n","    chat = model.start_chat(\n","        history=request_body['history']\n","    )\n","    prompt = request_body[\"prompt\"]\n","    response = chat.send_message(prompt, generation_config=request_body[\"generation_config\"])\n","    return response\n","\n","def accept_Gemini_response(response):\n","    res_stop = True\n","    # first check if the response is complete\n","    if not response._done:\n","        res_stop = False\n","\n","    # Other checks in the future\n","    return res_stop\n","\n","def query_Gemini(**request_body):\n","    response = try_query_Gemini(**request_body)\n","    # if response failed\n","    timeout = 0\n","    while not accept_Gemini_response(response):\n","        response = try_query_Gemini(**request_body)\n","        timeout += 1\n","        if timeout > 10:\n","            raise Exception(\"Query failed\")\n","    return response\n","\n","\n","class GeminiChatBot:\n","    def __init__(self, system_prompt=\"You are a helpful assistant.\", gemini_model=\"gemini-1.5-flash\", temperature=0.7):\n","        genai.configure(api_key=GEMINI_KEY)\n","        self.model = genai.GenerativeModel(model_name=gemini_model, system_instruction=system_prompt)\n","        self.generation_config = genai.types.GenerationConfig(temperature=temperature)\n","        self.chat_history = []\n","\n","\n","\n","\n","    def chat(self, prompt):\n","        '''\n","        for gemini we are not puting a interactive chatbot with history, just zero shot.\n","        No need to add the print feature\n","        '''\n","        request_body = {\n","            \"model\": self.model,\n","            \"generation_config\": self.generation_config,\n","            \"history\" : self.chat_history,\n","            \"prompt\": prompt,\n","        }\n","        response = query_Gemini(**request_body)\n","\n","        return response.text\n","    def set_chat_history(self, chat_history):\n","        self.chat_history = chat_history\n","\n"]},{"cell_type":"markdown","source":["# Anagram"],"metadata":{"id":"Ee1M0HwkdmHy"}},{"cell_type":"code","source":["def solve_simple_anagram(sample, chat_bot, information_extractor):\n","    # get the clue\n","    clue = sample['clue']\n","    # Remove the tuple at the end (assuming there are no other parenthsis in the clue.), Remove periods and commas\n","    clue = re.sub(r\"[^a-zA-Z']\", ' ', clue)\n","    # Split the clue into a list of words\n","    word_list = clue.split()\n","    # get the word length for each word in clue\n","    word_len_list = [len(word) for word in word_list]\n","\n","    # get enumeration\n","    enumeration = sample[\"enumeration\"]\n","    # get the number of letters of the answer (add all the numbers in enumeration)\n","    if '-' in enumeration:\n","        split_sign = '-'\n","    else:\n","        split_sign = ','\n","    numbers_list = enumeration.strip('()').split(split_sign)\n","    answer_letter_numbers = [int(num) for num in numbers_list]\n","    # get the word length for answer\n","    answer_letter_len = sum(answer_letter_numbers)\n","    # get number of words (see how many numbers are there in enumeration)\n","    answer_word_len = len(answer_letter_numbers)\n","\n","    # get all potential anagram phrases\n","    potential_anagram_phrases = []\n","    for k in range(len(word_list)-1):\n","        continue_checking = False\n","        for i in range(len(word_list) - k):\n","            if sum(word_len_list[i:i+k+1]) == answer_letter_len:\n","                potential_anagram_phrases.append(\" \".join(word_list[i:i+k+1]))\n","            if sum(word_len_list[i:i+k+1]) < answer_letter_len:\n","                # as long as there is still one combination of k words that is smaller than answer_letter_len, we continue\n","                continue_checking = True\n","        if continue_checking == False:\n","            break\n","\n","    # if there is no potential anagrams from the words of clue, then it cannot be solved.\n","    if len(potential_anagram_phrases) == 0:\n","        return None\n","\n","    # Iteration 1: Get Shuffle_phrase, Indicator, Definition\n","    prompt = f\"Given the cryptic crossword puzzle '{clue}', I know that it is a anagram type crossword puzzle. The hint number suggests that the shape of the answer is {enumeration}, so that means the phrase we want to shuffle have exacty {answer_letter_len} english letters. Here are all the phrases in the clue that satisfies this requirement: {potential_anagram_phrases}. I need to pick from them the most likely phrase to shuffle. \\nFor each of the potential phrase to shuffle, what's left in the clue will consists of the indicator and definition (Indicator are words that indicate this clue is an anagram, definition are words that defines the answer). I want you to solve this problem by the following steps: You will first try to identify the indicator and definition from what's left inside the clue. Then you will look at the potential indicator and definition you picked, and decide if the indicator is actually likely to be an indicator of an anagram. If yes, then the phrase is likely to be the phrase we want to shuffle.\"\n","    response = chat_bot.chat(prompt)\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, \\nwhat are all the phrase to shuffle, the indicator and the definition? Give me in the form of tuple of three strings: (<phrase>, <indicator>, <definition>), I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    parsed_tuple = ast.literal_eval(response_extract)\n","    shuffle_phrase, indicator, definition = parsed_tuple\n","\n","    # Iteration 2: Perform Anagram and Get Answer\n","    if answer_word_len > 1:\n","        # Prompt for two words answer (Reminder: add possibility to invert the order.)\n","        prompt_3 = f\"Given the cryptic crossword puzzle {clue}, I know that it is a anagram type crossword puzzle becasue {indicator} is an indicator phrase. The hint number suggests that the shape of the answer is {enumeration}, so that means the phrase we want to shuffle have exacty {answer_letter_len} english letters. We know that the phrase we want to shuffle is {shuffle_phrase}, because this phrase have exactly {answer_letter_len} english letters. Now, given this phrase to shuffle, I want you to follow these steps to find the answer: since the answer have more than one word, you will list all the letters that is the avalible for building words. Then you will try to find the first word, and see what letters are left after building this first word. Finally you will find what word the rest of the letters can form. (try several times if it didn't work) There might be many, if there are many possibilities, you shoud consider which one fits the definition the best. \"\n","\n","    else:\n","        # prompt for one word answer: shuffle letters to get the results\n","        prompt_3 = f\"Given the cryptic crossword puzzle {clue}, I know that it is a anagram type crossword puzzle becasue {indicator} is an indicator phrase. The hint number suggests that the shape of the answer is {enumeration}, so that means the phrase we want to shuffle have exacty {answer_letter_len} english letters. We know that the phrase we want to shuffle is {shuffle_phrase}, because this phrase have exactly {answer_letter_len} english letters. Now, given this phrase to shuffle, I want you to follow these steps to find the answer: you will first list all the letters that is the avalible for building words, and then base on these letter, you will find the answer for this puzzle. \"\n","    response = chat_bot.chat(prompt_3)\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, What is the answer? I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","\n","    # return the answer\n","    return response_extract"],"metadata":{"id":"6eJyx3qD2zfV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Charade\n","Solve simple Charade doesn't need iterative prompting, just Naive CoT + In Context Learning"],"metadata":{"id":"Oh_gUIJWX7mB"}},{"cell_type":"code","source":["def solve_charade(sample,chat_bot, information_extractor):\n","    clue = sample['clue']\n","    enumeration = sample['enumeration']\n","    # get enumeration\n","    enumeration = sample[\"enumeration\"]\n","    # get the number of letters of the answer (add all the numbers in enumeration)\n","    if '-' in enumeration:\n","        split_sign = '-'\n","    else:\n","        split_sign = ','\n","    numbers_list = enumeration.strip('()').split(split_sign)\n","    answer_letter_numbers = [int(num) for num in numbers_list]\n","    # get the word length for answer\n","    answer_letter_len = sum(answer_letter_numbers)\n","    # get number of words (see how many numbers are there in enumeration)\n","    answer_word_len = len(answer_letter_numbers)\n","\n","    prompt = f\"\"\"in cryptic crossword puzzles there is a type called charade. each word or phrase in the clue represents another little piece of the answer, presumably in a misleading way, and you stitch them together to get a result.\n","    The clue is build with definition and components. by default the components should be used in the order they're presented in, but words like \"after\" can indicate re-arrangement.\n","    Charade Clue Structure: The clue contains these parts -\n","    1. Main Definition\n","    2. Charade Component Definitions - Definitions of the parts that make up the solution.\n","    the answer must be logical with the definition.\n","    the numbers at the end of the clue represent the amount of letter at each word.\n","\n","    the solution MUST be built from the components and the final answer must suit the definition.\n","    also they amount of letters must fit to the numbers at the end of the clue.\n","    here are few examples:\n","\n","    1:\n","    clue: \"Noodles,\" mafia man, is coming after you (4)\n","    answer: UDON\n","    explanation: The answer is UDON, a type of noodle (noodles is the definition), where DON (a “mafia man”, a component) comes after the letter U (“you”, another component)\n","\n","    2:\n","    clue: Small crew’s power source (5)\n","    answer: STEAM\n","    explanation: The answer is STEAM, a type of \"power source\" (this is the definition), and the wordplay is S (short for “small”) plus TEAM (a synonym for “crew”)\n","\n","    3:\n","\n","    clue: Wet season soon after Monday (7)\n","    answer: MONSOON\n","    explanation: Put SOON after MON, a common abbreviation for “Monday,” to get MONSOON (“wet season”, this is the definition)\n","\n","    now i want you to solve me the next puzzle which is a charade type. the components MUST be logical and also the answer must be reasonable with the definition.\n","    Consider multiple interpretations for each component and explore all possible combinations to fit the definition and letter count\n","\n","    clue: {clue}\n","    the answer MUST contain {answer_word_len} words {answer_letter_len} letters.\n","    the answer MUST be derived from the components.\n","    the answer MUST fit to the definition.\n","\n","    what is the answer?\"\"\"\n","    response = chat_bot.chat(prompt)\n","    prompt_extract = f\"Given the output:\\n{response}, What is the answer? I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","\n","    return response_extract"],"metadata":{"id":"2pVpGD-EWNuX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Containers\n","Solve simple Containers doesn't need iterative prompting, just Naive CoT + In Context Learning"],"metadata":{"id":"wglD0OcHBZlI"}},{"cell_type":"markdown","source":["# Letter Selection - Deletion\n","Solve simple Containers doesn't need iterative prompting, just Naive CoT + In Context Learning"],"metadata":{"id":"JbDKHjZlBdZE"}},{"cell_type":"markdown","source":["# Double Definition"],"metadata":{"id":"zPq8qgHakQy_"}},{"cell_type":"code","source":["def solve_double_definition(sample, chat_bot, information_extractor):\n","    clue = sample['clue']\n","    enumeration = sample['enumeration']\n","\n","    # Get the two definition from the sentence\n","    prompt = f\"Given the cryptic crossword puzzle {clue}, I know that it is a double definition type crossword puzzle, which means the clue may, rather than having a definition part and a wordplay part, have two definition parts. Can you split this sentence, and tell me what are the two definition phrases of the answer? In order to be more accurate, I want you to follow the following steps: \\nFIRST you will try to find the first phrase that might be the first definition (start with the first word and check how much of the sentence can form a meaningful definition). \\nSecond, you will see what is left in the sentence. \\n THIRD, you will determine if your division is correct by checking if the phrase that's left can be a meaningful definiton of something. \\nFOURTH, you will look at each definitions, and interpret what they could mean, what could they be referring to (there might be multiple meanings, and I want you to list all possible meanings of this definition). \\FIFTH, you will put all the interpretations together into a list. \"\n","    response = chat_bot.chat(prompt)\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, What is the the two definition phrases, and what are the bucket of interpretations?  Give me in the form of tuple of three strings: (<definition 1>, <definition 2>, <interpretations>) I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    definition_1, definition_2, interpretations = ast.literal_eval(response_extract)\n","\n","    # Get the Answer\n","    prompt = f\"Given the cryptic crossword puzzle {clue}, I know that it is a double definition type crossword puzzle, which means the clue may, rather than having a definition part and a wordplay part, have two definition parts. After looking at the clue, I think the first part of the definition is {definition_1}, and the rest of the sentence formed the second part of the definition: {definition_2}. The hint number suggests that the shape of the answer is {enumeration}. Therefore, the possible answer should be a {enumeration} shaped word that fits both definitions, something that relates to '{interpretations}'.So now, I want you to solve the problem this way:\\nFIRST, you will think of some words with shape {enumeration}, that relates to '{interpretations}' ---- words that fits under the definiton of both '{definition_1}' and '{definition_2}'. \\n SECOND, for each word you listed, check if they can both fit the definition of '{definition_1}' and '{definition_2}', and give an brief explanation. \\nFINALLY, conclude the answer based on your analysis.\"\n","    response = chat_bot.chat(prompt)\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, What is the answer? I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","\n","    return response_extract\n"],"metadata":{"id":"Uxb6kxJC9hxB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hidden Words"],"metadata":{"id":"jhW22UkVnWXA"}},{"cell_type":"code","source":["def solve_simple_hidden_word(sample, chat_bot, information_extractor):\n","    clue = sample[\"clue\"]\n","    # get enumeration\n","    enumeration = sample[\"enumeration\"]\n","    # get the number of letters of the answer (add all the numbers in enumeration)\n","    if '-' in enumeration:\n","        split_sign = '-'\n","    else:\n","        split_sign = ','\n","    numbers_list = enumeration.strip('()').split(split_sign)\n","    answer_letter_numbers = [int(num) for num in numbers_list]\n","    # get the word length for answer\n","    answer_letter_len = sum(answer_letter_numbers)\n","    # get number of words (see how many numbers are there in enumeration)\n","    answer_word_len = len(answer_letter_numbers)\n","\n","    # Iteration 1: get hidden_phrase, indicator, definition\n","    prompt = f\"Give the cryptic crossword puzzle '{clue}', I know that this puzzle is a hidden word type of cryptic crossword puzzles, that means the answer is somewhere written within the clue – either as part of a longer word or across more than one word. What is the indicator phrase that indicates this is a hidden word puzzle? And in that case, which phrase might hide the answer? Finally, which phrase is the definition?\"\n","    response = chat_bot.chat(prompt)\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, what are the phrase that might hide the answer, the indicator and the definition? Give me in the form of tuple of three strings: (<phrase>, <indicator>, <definition>), I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    parsed_tuple = ast.literal_eval(response_extract)\n","    hidden_phrase, indicator, definition = parsed_tuple\n","\n","    # Hybrid Step: perform sliding window\n","    all_possible_hidden_words = []\n","    hidden_phrase = re.sub(r\"[^a-zA-Z]\", '', hidden_phrase)\n","    hidden_phrase = hidden_phrase.lower()\n","\n","    for i in range(len(hidden_phrase) - answer_letter_len + 1):\n","        phrase = hidden_phrase[i:i+answer_letter_len]\n","\n","        # given a phrase of crrect length, make it the correct size (size of enumeration)\n","        reshaped_string = []\n","        start = 0\n","        for num in answer_letter_numbers:\n","            # Extract the substring of length `num`\n","            part = phrase[start:start + num]\n","            reshaped_string.append(part)\n","            # Move the start index forward by `num`\n","            start += num\n","        # Join the parts with a space\n","        possible_hidden_word = ' '.join(reshaped_string)\n","        all_possible_hidden_words.append(possible_hidden_word)\n","\n","    # Iteration 2: Get the Answer\n","    prompt = f\"Give the cryptic crossword puzzle '{clue}', I know that this puzzle is a hidden word type of cryptic crossword puzzles, that means the answer is somewhere written within the clue – either as part of a longer word or across more than one word. I know that the word {indicator} indicates that the phrase '{hidden_phrase}' will have the answer. Also, the phrase '{definition}' is the definition of the phrase: I have already gave you the definition, so you should not find another definition in the clue yourself. So here are all the possible strings that is the shape of {enumeration} that comes from the phrase: {all_possible_hidden_words}\\nWhich one of them suits the given definition?\"\n","    response = chat_bot.chat(prompt)\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, What is the answer? I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    return response_extract"],"metadata":{"id":"tze-yWii-Q2x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tips: Initials/Finals"],"metadata":{"id":"EP-mvIwIBkC1"}},{"cell_type":"code","source":["def solve_initials_finals(sample, chat_bot, information_extractor):\n","\n","    clue = sample[\"clue\"]\n","    enumeration = sample[\"enumeration\"]\n","    # get the number of letters of the answer (add all the numbers in enumeration)\n","    numbers_list = enumeration.strip('()').split(',')\n","    enumeration_numbers = [int(num) for num in numbers_list]\n","    number_of_letters = sum(enumeration_numbers)\n","    # get number of words (see how many numbers are there in enumeration)\n","    number_of_words_in_answer = enumeration.count(',') + 1\n","\n","    # store the answer for comparison\n","    answer = sample['answer']\n","\n","    if sample['is_initial']:\n","        prompt_word_1 = 'initial'\n","    if sample['is_final']:\n","        prompt_word_1 = 'final'\n","\n","    # We will get the initials/finals of the entire sentence (sometimes rest of sentence doesn't work)\n","    word_list = re.sub(r'[^a-zA-Z]', ' ', clue).lower().split()\n","    if sample['is_initial']:\n","        # initial means we will take word[:k] where k = 1\n","        concat_tips = [word[:1] for word in word_list]\n","        concat_tips = ''.join(concat_tips)\n","    else:\n","        # todo: here we assume initial and final, but no reverse (reverse the order of the letters)\n","        concat_tips = [word[-1:] for word in word_list]\n","        concat_tips = ''.join(concat_tips)\n","    # Now we will sliding window to all the possible answers.\n","    all_possible_answers = []\n","    for i in range(len(concat_tips) - number_of_letters + 1):\n","        phrase = concat_tips[i:i+number_of_letters]\n","\n","        # given a phrase of crrect length, make it the correct size (size of enumeration)\n","        reshaped_string = []\n","        start = 0\n","        for num in enumeration_numbers:\n","            # Extract the substring of length `num`\n","            word = phrase[start:start + num]\n","            reshaped_string.append(word)\n","            # Move the start index forward by `num`\n","            start += num\n","        # Join the parts with a space\n","        phrase = ' '.join(reshaped_string)\n","\n","        all_possible_answers.append(phrase)\n","    all_possible_answers\n","\n","\n","    # Some of the stuff in this prompt can be done through algorithm.... Adding structural input (Stressing the FIRST, SECOND, THIRD). Also I like this chain of thought proces, need to conclude it and see how to trasnfer to another kind. (Finding definition and indicator, somewhat seperate to answer phrase, but leave possibility to it. Check is possible answers are meaningful before continuing. Check all possibilities, and compare the probability. )\n","    prompt = f\"Give the cryptic crossword puzzle '{clue}', I know that this puzzle is a '{prompt_word_1}' type of cryptic crossword puzzles. The number in the clue hints that the answer is in shape {enumeration}, and the answer will be {number_of_letters} letters long. So if we take all the {prompt_word_1} letters of the the words in '{clue}' in order, we will form the string '{concat_tips}'. Then all the possible ansers are substrings of it (the consecutive substrings), so we get all possible answers: {all_possible_answers}. I want you to follow the following steps: For each string in the possible answers, \\nFIRST, determine if it is a meaningful term. \\nSECOND, if it's somewhat meaningful, What is the phrase in the original clue whose {prompt_word_1} letters formed this string. \\nTHIRD, usually the phrase that forms answer will not intersect with the indicator phrase and definition phrase (sometimes there might be), so try to find what can be the indicator that indicate this puzzle is a '{prompt_word_1}' type of cryptic crossword puzzles, and what is the phrase that's left that might be the definition (Sometimes the definition might be the entire sentence, then this rule doesn't work). FOURTH, check if the definition we found suits the string's meaning. FINALLY, conclude that which string among all possible ansers are the actual answer.\"\n","\n","    response = chat_bot.chat(prompt)\n","    # print(response)\n","\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, What is the answer? I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    return response_extract\n"],"metadata":{"id":"VTgWwpKICO8J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Alternate: Even/Odd"],"metadata":{"id":"9BQErBlLBpFI"}},{"cell_type":"code","source":["def solve_even_odd_letters(sample, chat_bot, information_extractor):\n","    clue = sample[\"clue\"]\n","    enumeration = sample[\"enumeration\"]\n","    # get the number of letters of the answer (add all the numbers in enumeration)\n","    numbers_list = enumeration.strip('()').split(',')\n","    enumeration_numbers = [int(num) for num in numbers_list]\n","    number_of_letters = sum(enumeration_numbers)\n","    # get number of words (see how many numbers are there in enumeration)\n","    number_of_words_in_answer = enumeration.count(',') + 1\n","\n","    # store the answer for comparison\n","    answer = sample['answer']\n","\n","    # concatenate all the alternating sequences.\n","    clue_letters = re.sub(r\"[^a-zA-Z]\", '', clue).lower()\n","    even_letter_seq = clue_letters[::2]\n","    odd_letter_seq = clue_letters[1::2]\n","\n","    # We will get all possibilities from both even and odd, and for the model to choose?\n","    all_possible_answers = []\n","\n","    for letter_seq in [even_letter_seq, odd_letter_seq]:\n","        for i in range(len(letter_seq) - number_of_letters + 1):\n","            phrase = letter_seq[i:i+number_of_letters]\n","\n","            # given a phrase of crrect length, make it the correct size (size of enumeration)\n","            reshaped_string = []\n","            start = 0\n","            for num in enumeration_numbers:\n","                # Extract the substring of length `num`\n","                word = phrase[start:start + num]\n","                reshaped_string.append(word)\n","                # Move the start index forward by `num`\n","                start += num\n","            # Join the parts with a space\n","            phrase = ' '.join(reshaped_string)\n","\n","            all_possible_answers.append(phrase)\n","    all_possible_answers\n","\n","    # start the prompt\n","    prompt = f\"Give the cryptic crossword puzzle '{clue}', I know that this puzzle is a 'alternate letters' type of cryptic crossword puzzles. So if we take all the even letters of the clue, we will have '{even_letter_seq}', if we take all the odd letters of the clue, we will have '{odd_letter_seq}'. The number in the clue hints that the answer is in shape {enumeration}, and the answer will be {number_of_letters} letters long. Then all the possible ansers are substrings of it (the consecutive substrings), so we get all possible answers: {all_possible_answers}. I want you to follow the following steps: For each string in the possible answers, \\nFIRST, determine if it is a meaningful term. \\nSECOND, usually the phrase that forms answer will not intersect with the indicator phrase and definition phrase (sometimes there might be), so try to find what can be the indicator that indicate this puzzle is a 'alternate letters' type of cryptic crossword puzzles, and what is the phrase that's left that might be the definition (Sometimes the definition might be the entire sentence, then this rule doesn't work). THIRD, check if the definition we found suits the string's meaning. FINALLY, conclude that which string among all possible ansers are the actual answer.\"\n","\n","    response = chat_bot.chat(prompt)\n","    # print(response)\n","\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, What is the answer? I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    return response_extract\n"],"metadata":{"id":"wy27r79oCcEF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Homophones"],"metadata":{"id":"wYSLUi4KBrzj"}},{"cell_type":"markdown","source":["# Letter Banks"],"metadata":{"id":"d9_xf5QZBu3-"}},{"cell_type":"code","source":["def solve_letter_bank(sample, chat_bot, information_extractor):\n","\n","    clue = sample['clue']\n","    clue = re.sub(r\"[^a-zA-Z']\", ' ', clue)\n","    # get letter bank of clue\n","    clue_word_list = clue.lower().split()\n","\n","    # get the letter bank for answer: From previous mapping, we already know answer only have english letters and space.\n","    answer = sample['answer'].lower()\n","    answer_word_list = answer.split()\n","\n","    # get the answer length from enumeration field (I am lazy, just get it from answer field)\n","    enumeration = sample['enumeration']\n","    answer_length = len(answer)\n","\n","    # First check if clue letter bank contains all letters of answers (Here we assume that is true: Later when writting classifiers we will think otherwise)\n","\n","    # Now we find all possible isograms\n","    all_isograms = []\n","    for k in range(len(clue_word_list)-1):\n","        continue_checking_because_isogram_exists = False\n","        for i in range(len(clue_word_list) - k):\n","            # k_word_combo is ''.join(clue_word_list[i:i+k+1], letter bank of k_word_combo is set(k_word_combo)\n","            k_word_combo = ''.join(clue_word_list[i:i+k+1])\n","            k_word_combo_letter_bank = set(k_word_combo)\n","\n","            # if the length of k_word_combo is bigger than answer length, than even if it's isogram, it's not the letter bank of the answer. Also, this isogram shouldn't be counted as isogram exist: If beside from this, all other k_word_combo are not isogram, then for larger k, this will not be a suitable isogram, and the rest of the others will not be isogram at all.\n","            if len(k_word_combo_letter_bank) > answer_length:\n","                continue\n","\n","            # The we need to check if the k_word_combo is a isogram (It's a rule for letter bank)\n","            if len(k_word_combo_letter_bank) == len(k_word_combo):\n","                # if all the k_word_combo are not isogram, then for larger k, there will not be isogram.\n","                continue_checking_because_isogram_exists = True\n","                all_isograms.append(' '.join(clue_word_list[i:i+k+1]))\n","\n","            else:\n","                continue\n","\n","        if continue_checking_because_isogram_exists==False:\n","            break\n","\n","\n","\n","    # Now we let LLM handle the rest\n","    prompt = f\"Given the cryptic crossword puzzle {clue}, I know that it is a letter bank type crossword puzzle, which means there are an isogram in the clue (isogram is a word/phrase containing no repeated letters), and the answer are formed by by using each of these letters (but no others) at least once but repeating them as often as necessary. According to this rule, here are all possible isograms in this clue: {all_isograms}. And also, the hint number in the clue suggests that the answer is of shape {enumeration}. So now, I want you to solve the problem this way: \\nFIRST, you will find the indicator phrase (the phrase that indicate that this puzzle is a letter bank type crossword puzzle), since letter bank puzzles resenbles to anagram puzzles, their indicators might also be similar; and then you will find the definition phrase (The phrase that gives definition to the answer). Of course you will not be sure, but you will look at what is the most likely phrase for each. \\nSECOND, based on the indicator phrase and definition phrase, you can guess which isogram in the list of all possible isograms is the isogram that could potentially form the answer. (Usually the indicator phrase, the isogram and the definition phrase will not overlap, that means they will not share the same words in the clue). \"\n","\n","    response = chat_bot.chat(prompt)\n","\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, what are all the phrase to shuffle, the indicator, the definition and the isogram that the LLM chose? Give me in the form of tuple of three strings: (<indicator>, <definition>, <isogram>), I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    parsed_tuple = ast.literal_eval(response_extract)\n","    indicator, definition, isogram = parsed_tuple\n","    # print(parsed_tuple)\n","\n","    sample# randomly suffle the letters\n","    list_of_letters = list(set(isogram))\n","    random.shuffle(list_of_letters)\n","\n","    prompt = f\"\"\"Given the cryptic crossword puzzle {clue}, the indicator phrase '{indicator}' suggests that it is a letter bank type crossword puzzle, which means there are an isogram in the clue (isogram is a word/phrase containing no repeated letters), and the answer are formed by by using each of these letters (but no others) at least once but repeating them as often as necessary. And the phrase '{definition}' is likely the definition phrase that defines the answer. So based on the indicator phrase and definition phrase, we conclude that the isogram '{isogram}' is the isogram tha we use to construct the answer. And also, the hint number in the clue suggests that the answer is of shape {enumeration}. \\n\n","    Now, I want you to solve the problem this way: \\n\n","    Generate a word that:\\n\n","    1. Matches the shape: {enumeration}\\n\n","    2. Has the meaning: \"{definition}\"\\n\n","    3. Uses every letters in {list_of_letters}, at least once (repetitions allowed).\\n\n","    4. Does not use any letters outside this list. \\n\n","    \"\"\"\n","    response = chat_bot.chat(prompt)\n","    # print(response)\n","\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, What is the answer? I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    return response_extract\n"],"metadata":{"id":"u-AHhy4TCm-a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Reversals"],"metadata":{"id":"E15jmnubBzpa"}},{"cell_type":"markdown","source":["# Palindrome"],"metadata":{"id":"Rt_7BhonB4RO"}},{"cell_type":"code","source":["def solve_palindrom(sample, chat_bot, information_extractor):\n","\n","    clue = sample['clue']\n","    # Remove the tuple at the end (assuming there are no other\n","    clue = re.sub(r\"[^a-zA-Z']\", ' ', clue).lower()\n","\n","    # things about enumeration\n","    enumeration = sample[\"enumeration\"]\n","    # get the number of letters of the answer (add all the numbers in enumeration)\n","    numbers_list = enumeration.strip('()').split(',')\n","    enumeration_numbers = [int(num) for num in numbers_list]\n","    number_of_letters = sum(enumeration_numbers)\n","    # get number of words (see how many numbers are there in enumeration)\n","    number_of_words_in_answer = enumeration.count(',') + 1\n","\n","    # get the word length for answer\n","    answer = sample['answer'].lower().replace(\" \", \"\")\n","    answer_len = len(answer)    # technically just add all the number in enumeratio together, i am lazy.\n","\n","\n","\n","    prompt = f\"Given the cryptic crossword puzzle {clue}, I know that it is a pallindrom type crossword puzzle. The hint number suggests that the shape of the answer is {enumeration}, so that means the phrase we want to reverse have exacty {number_of_letters} english letters, and also it is a pallindrom. You will solve this problem by the following steps: \\nFirst, try to find the phrase that indicate that this puzzle is a pallindrom type crossword puzzle. \\nSECOND, given the sentence, you will think of some pallindrom that has {number_of_letters} english letters, that might relate to this sentence semantically ---- As many as possible! \\nTHIRD, Dobule check if the answers you gave are indeed pallindroms. FOURTH, check which one of the pallindroms suits the meaning of the sentence. FINALLY, conclude that which string among all possible ansers are the actual answer.\"\n","\n","    response = chat_bot.chat(prompt)\n","    # print(response)\n","\n","    # extract information\n","    prompt_extract = f\"Given the output:\\n{response}, What is the answer? I don't need other information.\"\n","    response_extract = information_extractor.chat(prompt_extract)\n","    return response_extract\n"],"metadata":{"id":"PWAc4S61C2In"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Chatbot"],"metadata":{"id":"tcV4mqeR2GIh"}},{"cell_type":"code","source":["\n","def load_gpt_chat_bot(gpt_model = \"gpt-4o-2024-08-06\"):\n","    solver_system_prompt = \"You are a helpful assistant. You are very good at solving cryptic crossword puzzles. \"\n","    request_body = {\n","        \"model\": gpt_model,\n","        \"messages\": [{\"role\": \"system\", \"content\": solver_system_prompt}],\n","        \"temperature\": 0.7,\n","    }\n","    chat_bot = GPTChatBot(request_body)\n","\n","    extractor_system_prompt = \"You are served as a information extractor. You will be given the output of an LLM, and a question, and from the given output, you will extract the information that answers the question. Your output will be linked to a computer program, so you will be accurate and concise.\"\n","\n","    # Load the 4o extractor instead\n","    request_body = {\n","        \"model\": \"gpt-4o-2024-08-06\",   # only the 4o model is good enough\n","        \"messages\": [{\"role\": \"system\", \"content\": extractor_system_prompt}],\n","        \"temperature\": 0.2,\n","    }\n","    information_extractor = GPTChatBot(request_body)\n","    return chat_bot, information_extractor\n"],"metadata":{"id":"a_9i_dCo2STu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_gemini_chat_bot(gemini_model = \"gemini-1.5-pro\"):\n","    solver_system_prompt = \"You are a helpful assistant. You are very good at solving cryptic crossword puzzles. \"\n","\n","    chat_bot = GeminiChatBot(system_prompt=solver_system_prompt, gemini_model=gemini_model, temperature=0.7)\n","\n","    extractor_system_prompt = \"You are served as a information extractor. You will be given the output of an LLM, and a question, and from the given output, you will extract the information that answers the question. Your output will be linked to a computer program, so you will be accurate and concise.\"\n","\n","    # information_extractor = GeminiChatBot(system_prompt=extractor_system_prompt, gemini_model=gemini_model, temperature=0.2)\n","\n","    # Load the 4o extractor instead\n","    request_body = {\n","        \"model\": \"gpt-4o-2024-08-06\",   # only the 4o model is good enough\n","        \"messages\": [{\"role\": \"system\", \"content\": extractor_system_prompt}],\n","        \"temperature\": 0.2,\n","    }\n","    information_extractor = GPTChatBot(request_body)\n","    return chat_bot, information_extractor"],"metadata":{"id":"X5Zi5EcY279i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Test results\n","We will test for the success rate for this approach."],"metadata":{"id":"00BeGsFr8DUZ"}},{"cell_type":"code","source":["dataset_hgggingface_dir = f'PromptEngineering/ProcessedDatasets/recognizable_data/'\n","datasets = load_from_disk(dataset_hgggingface_dir)"],"metadata":{"id":"Ty4lAHJO2Jcr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from joblib import Memory\n","gemini_pro = \"gemini-1.5-pro\"\n","gemini_flash = \"gemini-1.5-flash\"\n","gpt_4o = \"gpt-4o-2024-08-06\"\n","gpt_4o_mini = \"gpt-4o-mini\"\n","\n","# Work around for joblib caching in jupyter notebook \"joblib persistence across sessions/machines\"\n","def cache(mem, module, **mem_kwargs):\n","    # model is the notebook/python file name: Jupyter notebook's name is always changing so we need this work around\n","    def cache_(f):\n","        f.__module__ = module\n","        f.__qualname__ = f.__name__\n","        return mem.cache(f, **mem_kwargs)\n","    # return the cache function that will always create same name for cahce directory\n","    return cache_\n","\n","# Create a memory object with a cache directory\n","memory = Memory(location=\"PromptEngineering/FunctionCache\", verbose=0)"],"metadata":{"id":"gPcaC2Yomwxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocessing_added_columns = ['is_charade', 'is_double_definition', 'is_anagram', 'type', 'is_hidden_word', 'is_initial', 'is_final', 'is_even_letter', 'is_odd_letter', 'is_reverse', 'is_pallindrom', 'is_letter_bank']"],"metadata":{"id":"6ZcnJW5bnRvl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","def cache_test_all_models(solvables, solver_function, max_test_size=20):\n","    test_size = min(len(solvables), max_test_size)\n","\n","    model_score = {'test_size': test_size, gemini_pro: 0, gemini_flash: 0, gpt_4o: 0, gpt_4o_mini: 0}\n","    for model in [gemini_flash, gemini_pro, gpt_4o, gpt_4o_mini]:\n","        for i in tqdm(range(test_size), ncols=100):\n","            sample = solvables[i]\n","            try:\n","                # cache the function\n","                response_extract = solver_function(sample, model, attempt=1)\n","                if response_extract.strip().lower() == sample['answer'].strip().lower():\n","                    model_score[model] += 1\n","            except:\n","                print(f\"Failed to solve puzzle {i} with model {model}\")\n","                continue\n","            # response_extract = solver_function(sample, model, attempt=1)\n","    return model_score\n"],"metadata":{"id":"IIOuAhNgMlwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title All Wrappers\n","# Carefullll Do not change this code!!!!\n","\n","@cache(memory, \"CoT\")\n","def solve_anagram_wrapper(sample, model, attempt=1):\n","    if \"gemini\" in model:\n","        chat_bot, information_extractor = load_gemini_chat_bot(model)\n","    else:\n","        chat_bot, information_extractor = load_gpt_chat_bot(model)\n","    response_extract = solve_simple_anagram(sample, chat_bot, information_extractor)\n","    return response_extract\n","\n","\n","@cache(memory, \"CoT\")\n","def solve_charade_wrapper(sample, model, attempt=1):\n","    if \"gemini\" in model:\n","        chat_bot, information_extractor = load_gemini_chat_bot(model)\n","    else:\n","        chat_bot, information_extractor = load_gpt_chat_bot(model)\n","    response_extract = solve_charade(sample, chat_bot, information_extractor)\n","    return response_extract\n","\n","\n","@cache(memory, \"CoT\")\n","def solve_double_wrapper(sample, model, attempt=1):\n","    if \"gemini\" in model:\n","        chat_bot, information_extractor = load_gemini_chat_bot(model)\n","    else:\n","        chat_bot, information_extractor = load_gpt_chat_bot(model)\n","    response_extract = solve_double_definition(sample, chat_bot, information_extractor)\n","    return response_extract\n","\n","@cache(memory, \"CoT\")\n","def solve_hidden_wrapper(sample, model, attempt=1):\n","    if \"gemini\" in model:\n","        chat_bot, information_extractor = load_gemini_chat_bot(model)\n","    else:\n","        chat_bot, information_extractor = load_gpt_chat_bot(model)\n","    response_extract = solve_simple_hidden_word(sample, chat_bot, information_extractor)\n","    return response_extract\n","\n","\n","@cache(memory, \"CoT\")\n","def solve_tip_wrapper(sample, model, attempt=1):\n","    if \"gemini\" in model:\n","        chat_bot, information_extractor = load_gemini_chat_bot(model)\n","    else:\n","        chat_bot, information_extractor = load_gpt_chat_bot(model)\n","    response_extract = solve_initials_finals(sample, chat_bot, information_extractor)\n","    return response_extract\n","\n","\n","@cache(memory, \"CoT\")\n","def solve_alternate_wrapper(sample, model, attempt=1):\n","    if \"gemini\" in model:\n","        chat_bot, information_extractor = load_gemini_chat_bot(model)\n","    else:\n","        chat_bot, information_extractor = load_gpt_chat_bot(model)\n","    response_extract = solve_even_odd_letters(sample, chat_bot, information_extractor)\n","    return response_extract\n","\n","\n","@cache(memory, \"CoT\")\n","def solve_letter_bank_wrapper(sample, model, attempt=1):\n","    if \"gemini\" in model:\n","        chat_bot, information_extractor = load_gemini_chat_bot(model)\n","    else:\n","        chat_bot, information_extractor = load_gpt_chat_bot(model)\n","    response_extract = solve_letter_bank(sample, chat_bot, information_extractor)\n","    return response_extract\n","\n","@cache(memory, \"CoT\")\n","def solve_palindrome_wrapper(sample, model, attempt=1):\n","    if \"gemini\" in model:\n","        chat_bot, information_extractor = load_gemini_chat_bot(model)\n","    else:\n","        chat_bot, information_extractor = load_gpt_chat_bot(model)\n","    response_extract = solve_palindrom(sample, chat_bot, information_extractor)\n","    return response_extract\n"],"metadata":{"id":"OiIc7MKaNoyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Test Anagram\n","solvables = datasets.filter(lambda sample: sample['is_anagram'] == True)\n","solvables = solvables.remove_columns(preprocessing_added_columns)\n","\n","cache_test_all_models(solvables['test'], solver_function=solve_anagram_wrapper)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"ew-J5E-Pp4SV","executionInfo":{"status":"ok","timestamp":1726330655678,"user_tz":-180,"elapsed":11414,"user":{"displayName":"Sam Yiin","userId":"15309663941607315772"}},"outputId":"0740cc14-c61e-4962-d9ef-00927b0aaff8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 77.83it/s]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 81.34it/s]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [00:10<00:00,  1.91it/s]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 88.89it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_size': 20,\n"," 'gemini-1.5-pro': 5,\n"," 'gemini-1.5-flash': 1,\n"," 'gpt-4o-2024-08-06': 11,\n"," 'gpt-4o-mini': 3}"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["# @title Test charade\n","solvables = datasets.filter(lambda sample: sample['is_charade'] == True)\n","solvables = solvables.remove_columns(preprocessing_added_columns)['test']\n","cache_test_all_models(solvables, solver_function=solve_charade_wrapper)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"cellView":"form","id":"goIT_4C3v1hF","executionInfo":{"status":"ok","timestamp":1726331126680,"user_tz":-180,"elapsed":11083,"user":{"displayName":"Sam Yiin","userId":"15309663941607315772"}},"outputId":"24b34743-8fe2-49b8-ec70-ad80ad7d6459"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.56it/s]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [00:06<00:00,  3.07it/s]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 92.16it/s]\n","100%|██████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 108.73it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_size': 20,\n"," 'gemini-1.5-pro': 13,\n"," 'gemini-1.5-flash': 8,\n"," 'gpt-4o-2024-08-06': 12,\n"," 'gpt-4o-mini': 4}"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# @title Test Double definition\n","solvables = datasets.filter(lambda sample: sample['is_double_definition'] == True)\n","solvables = solvables.remove_columns(preprocessing_added_columns)['test']\n","cache_test_all_models(solvables, solver_function=solve_double_wrapper)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["97e85fae8bdb402db3a989687d3d6dbb","d1ed1cb713094aae8a95db63c9b2881c","83fde72fbdfa485fa45727279fb67349","a5edd04125f440fc93af024d440c249e","0a215093358a4b57979e4f7171e80a98","2186989c64904cb3bdf8840847025c1d","8a1377c5c3044bfd805c70c28170c0f7","02310bdea4554815b9c338eb4796d5d4","0c59788995324382a494493bcf8f0d54","ff5a9d33a2bb43aa9de7d5ecb1c7ef10","124ea7eaa5274aecb8acb59c19f4b623","804b04349c0d4fbe9c8fc70a07e5c67c","b630157fb31d4f97b3da504c4d7c7835","f86fa666217a4786a95bfd98386bae46","a2452758778b42569d1f3341a7a6e36e","381eea6101574ef59b00b7f75bca64d9","6deb57256b764788a326b4c1750508c7","3e71365f85d340d1921640d64285d308","5d074686ec7942f38f317834aa0992dd","d0648ca75ff6495daa9bcaa3d8a728fc","4fd607beac3245eeaa27947d1aad472b","baa6f4b5f58043d18ea34ddea479a35d","935c542cc5e0467e8e73d46326fdecfb","95254117931141909381645494be5a2c","769f71ff3c5045c4a2b2de0e09aec3b4","a05a71131b15496aa6015cb1de58003d","50e3fd6ca1d3482cb7ef8825a929e70f","abcba5d04ec54689aad9b86959288e99","c36038de8d8b47cc9521b8031601faee","6aef690deb0642e1bce60501f4d4a67d","c597f6537e66456c84a42804c7abe23e","5fcaecb891c04bc4ad1c92d9f5e22837","4ffc7f13a0b941caa84196860bf3ac77"]},"cellView":"form","id":"GW_9CUSKWLHZ","executionInfo":{"status":"ok","timestamp":1726331753411,"user_tz":-180,"elapsed":617065,"user":{"displayName":"Sam Yiin","userId":"15309663941607315772"}},"outputId":"241ed8c3-8c0a-4b11-acfa-6eb1eee9f28b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/470852 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97e85fae8bdb402db3a989687d3d6dbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/26204 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"804b04349c0d4fbe9c8fc70a07e5c67c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/26205 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"935c542cc5e0467e8e73d46326fdecfb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████████████████████████████| 13/13 [01:27<00:00,  6.75s/it]\n","100%|███████████████████████████████████████████████████████████████| 13/13 [03:17<00:00, 15.20s/it]\n","100%|███████████████████████████████████████████████████████████████| 13/13 [02:08<00:00,  9.88s/it]\n","100%|███████████████████████████████████████████████████████████████| 13/13 [03:04<00:00, 14.17s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_size': 13,\n"," 'gemini-1.5-pro': 4,\n"," 'gemini-1.5-flash': 3,\n"," 'gpt-4o-2024-08-06': 5,\n"," 'gpt-4o-mini': 3}"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# @title Test Hidden Words\n","solvables = datasets.filter(lambda sample: sample['is_hidden_word'] == True)\n","solvables = solvables.remove_columns(preprocessing_added_columns)['test']\n","cache_test_all_models(solvables, solver_function=solve_hidden_wrapper)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"t4G2N9PZWTYC","executionInfo":{"status":"ok","timestamp":1726334898822,"user_tz":-180,"elapsed":6150,"user":{"displayName":"Sam Yiin","userId":"15309663941607315772"}},"outputId":"a55f0101-f30c-4f91-e6d2-627d4e571bac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.71it/s]\n","100%|██████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 113.31it/s]\n","100%|██████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 117.26it/s]\n","100%|██████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 109.19it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_size': 20,\n"," 'gemini-1.5-pro': 5,\n"," 'gemini-1.5-flash': 6,\n"," 'gpt-4o-2024-08-06': 15,\n"," 'gpt-4o-mini': 11}"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["# @title Test initial/finals\n","solvables = datasets.filter(lambda sample: (sample['is_initial'] == True) or (sample['is_final'] == True))\n","solvables = solvables['test']\n","cache_test_all_models(solvables, solver_function=solve_tip_wrapper)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9fWvRk6WeDF","executionInfo":{"status":"ok","timestamp":1726335877979,"user_tz":-180,"elapsed":985,"user":{"displayName":"Sam Yiin","userId":"15309663941607315772"}},"outputId":"28e0a65b-901c-4029-ea72-ae0ebf4c2bba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 113.46it/s]\n","100%|██████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 108.83it/s]\n","100%|██████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 118.89it/s]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 98.12it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_size': 20,\n"," 'gemini-1.5-pro': 18,\n"," 'gemini-1.5-flash': 19,\n"," 'gpt-4o-2024-08-06': 20,\n"," 'gpt-4o-mini': 20}"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["# @title Test Alternate\n","solvables = datasets.filter(lambda sample: (sample['is_even_letter'] == True) or (sample['is_odd_letter'] == True))\n","solvables = solvables.remove_columns(preprocessing_added_columns)['test']\n","cache_test_all_models(solvables, solver_function=solve_alternate_wrapper)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["5f7ae90b3f0e40228388eb8f2be14c64","fd7d56a38c604dbbacbb1e7af7d200cb","e03f90459be8449aa36de54f4cf9a0c5","68f99457a7934e3dbd63055b1e9f8b58","137027f960c64dbea8447353bb53daa4","0abb9dba99d1461399814adbf9552309","5f21d8f9cd584cadb74ba83cac2f1004","8e6cea4b250640b7bc64c45ce6f7b4c3","7362a2cd22504914bb67fa3fdbb22572","29115e63703345b2b94d068431083b7e","90bf9eb5e04d40429f3d21f28564679f","bbaf7d6f23504741839ccff7e3d63a0e","136c0414109547918aab42f45fbed20d","6a1064ed48e34e1092d3bf86bc40a555","7f7599481f3e4890a8014a0879525627","9e2800cb67604a18abe8e77589144601","f5503edea32f49e19f2d977a5ceee449","313f9bd777a346a18f326ab8c7904967","03ccc546d2ce45418d1f532768ef2727","9358584b9d654a909c569bb6656eb06a","0c59fbcbc68240a0896a1f153c9498ab","7aa78b46b7c5431ebfc8e40b4688eec4","5ce0725a975b4afa8176e8cdf0e6ed7a","56e27008c83c4a819aa29b9998d07cdf","b56dfd9dabb84fd8a6ee20df725623a7","667964eed9d24ab396197e153e972219","133948056adf4610a5321e677642ab89","fd185af71dda44e69d35305fae71509e","4a47b368924d45c0bde64493e36fff25","f4a0b36a475d49679505dcae47f948c3","94e70a78f793480ab5e8bb5fa3b57559","44249b81909f43aea31d91315ad1cead","0b87a93848f44bfba1dd85d20ca19dbc"]},"id":"hILxfVthoRKx","executionInfo":{"status":"ok","timestamp":1726336426451,"user_tz":-180,"elapsed":547028,"user":{"displayName":"Sam Yiin","userId":"15309663941607315772"}},"outputId":"5c24cd67-7174-4124-a5cf-17ff6ea33a38"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/470852 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f7ae90b3f0e40228388eb8f2be14c64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/26204 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbaf7d6f23504741839ccff7e3d63a0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/26205 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ce0725a975b4afa8176e8cdf0e6ed7a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████████████████████████████| 20/20 [01:08<00:00,  3.44s/it]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [02:59<00:00,  8.99s/it]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [02:12<00:00,  6.61s/it]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [02:29<00:00,  7.48s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_size': 20,\n"," 'gemini-1.5-pro': 14,\n"," 'gemini-1.5-flash': 18,\n"," 'gpt-4o-2024-08-06': 15,\n"," 'gpt-4o-mini': 18}"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["# @title Test Palindrom\n","solvables = datasets.filter(lambda sample: sample['is_pallindrom'] == True)\n","solvables = solvables.remove_columns(preprocessing_added_columns)['test']\n","cache_test_all_models(solvables, solver_function=solve_palindrome_wrapper)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["fc3d415427e84a3f84cae38f7e507e2a","c85f4ecfd88a46e4ab54b43f37309de8","03ef5564247d49c6ad8ebb4363a6bc52","103541d5fa024060ae70800e38179973","b1b46c63023a4dee87581eae2ffc487f","5f9a49fc00b546e299310c0842e81fff","7187bae751514e3f94501a49e541177e","a2ed5d70b3f34beda475747a528b8410","da89f5bca2e54337b95434fb61002ab3","b4d4dada93184e9c89720be3e32d49d0","69cec636f2eb4d37bd50ecc555da2cb4","1d42c48d1a4d403c9ffee2d61ace185a","de77ca8dec9b44bc929aa5988955200c","d1726d1807d84c6cbf601d81b46c454e","b386a7f20ebc41aeb1a1fdf97522e7c4","c1665367e283484898ec119b18ffdd56","a9c4aa4aaee04d3ca49551b13de2111b","8056d88516dd44d1a9b550f509643caf","d6b4da3b5d2b4eb2a0ad85b63dc7f0ff","6cdaac3c4d544cd7ae07cb91354fb7c7","f4cdba5307df4dfb8796b1f4877fcb61","1f0da75170f54ee59457f51da5339f7d","ec9fdad12bb9488cab78219abbc2e80d","261442dc144f4987b7bd5eee197fd900","b8b8f8aaa88346668f6481792571dd69","b2916674b17c4679bbd623acd18c7e77","7574f1334a2b402c9ed0a4978c615ce7","8f2d1f7947394cea83ba24c41ab7a224","64436853845f4db1963cdff42c41a613","b5d3b558cbbd4453b8cad7022a7af121","307f9f71bd4e4bd887e1bd5272a5ddbb","b14f2b4a833a4a3f878a376c7ed9dff4","754006ba552d45748d07d7da690c9f53"]},"id":"qVRGku-Ao9Gq","executionInfo":{"status":"ok","timestamp":1726336838687,"user_tz":-180,"elapsed":412270,"user":{"displayName":"Sam Yiin","userId":"15309663941607315772"}},"outputId":"fd09230b-4d47-460d-f90c-dd43ac84d13f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/470852 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc3d415427e84a3f84cae38f7e507e2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/26204 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d42c48d1a4d403c9ffee2d61ace185a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/26205 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9fdad12bb9488cab78219abbc2e80d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████████████████████████████| 20/20 [01:12<00:00,  3.63s/it]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [02:24<00:00,  7.24s/it]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [01:31<00:00,  4.59s/it]\n","100%|███████████████████████████████████████████████████████████████| 20/20 [01:25<00:00,  4.30s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_size': 20,\n"," 'gemini-1.5-pro': 11,\n"," 'gemini-1.5-flash': 9,\n"," 'gpt-4o-2024-08-06': 15,\n"," 'gpt-4o-mini': 2}"]},"metadata":{},"execution_count":68}]}]}