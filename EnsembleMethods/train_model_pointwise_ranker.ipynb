{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to add cite to Generating clickbait spoilers with an ensemble of large language models article\n",
    "!pip install datasets transformers\n",
    "!pip install mlflow\n",
    "# userdata.get('secretName')\n",
    "# Import the necessary modules\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def prepare_data(args):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.model_name,\n",
    "        model_max_length=args.max_length,\n",
    "    )\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    data_dir = \"/path/to/your/dataset\"\n",
    "\n",
    "\n",
    "    tokenized_dataset = load_dataset('csv', data_files={'train': f'{data_dir}/train.csv', 'test': f'{data_dir}/test.csv'}).map(tokenize_function, batched=True)\n",
    "    tokenized_dataset = tokenized_dataset.rename_column(\"bleu\", \"label\")\n",
    "    return tokenizer, tokenized_dataset"
   ],
   "id": "38ad9e95805f3cee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(args, tokenizer, tokenized_clickbaits):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        args.model_name,\n",
    "        num_labels=1,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=args.output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=args.epochs,\n",
    "        learning_rate=args.learning_rate,\n",
    "        per_device_train_batch_size=args.batch_size,\n",
    "        per_device_eval_batch_size=args.batch_size,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=100,\n",
    "        push_to_hub=False,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"mlflow\",\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_clickbaits[\"train\"],\n",
    "        eval_dataset=tokenized_clickbaits[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "    return trainer"
   ],
   "id": "f9a2cb841528cd3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Args:\n",
    "    def __init__(self, model_name, output_dir, batch_size, epochs, learning_rate, max_length):\n",
    "        self.model_name = model_name\n",
    "        self.output_dir = output_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_length = max_length"
   ],
   "id": "fa05040c9e2a853e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main(args):\n",
    "    tokenizer, tokenized_clickbaits = prepare_data(args)\n",
    "\n",
    "    trainer = train(args, tokenizer, tokenized_clickbaits)\n",
    "    trainer.save_model()\n",
    "    tokenizer.save_pretrained(args.output_dir)"
   ],
   "id": "5547846e724634d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "args = Args(model_name='MateuszW/regressor-deberta-iter1-iter2', output_dir='models/regressor/deberta-finetuned', batch_size = 6, epochs = 3, learning_rate = 2e-6, max_length = 512)\n",
    "\n",
    "main(args)"
   ],
   "id": "d1f0406b7958126b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# model usage\n",
    "outputs = model(**inputs)\n",
    "predicted_value = outputs.logits.item()\n",
    "predicted_value"
   ],
   "id": "16c718df40074130"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
